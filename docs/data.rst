Data
====

Medical Images
--------------------

The dataset consists of 3T head MRIs of 100 unrelated subjects from the `Human Connectome Project (HCP) <https://www.humanconnectome.org/>`_ dataset of healthy volunteers [2]_.For each subject, the following data is available:

- T1-weighted MR image volume, not skull-stripped (but defaced for anonymization [3]_), and skull-stripped with a bias field correction
- T2-weighted MR image volume, processed the same way as the T1 image
- Both modalities in native T1 subject-space and in MNI-atlas space [4]_, see below
- The ground truth label maps
- and much more

The ground truth labels are generated by FreeSurfer (e.g., [5]_)  and are not manual expert annotations.
As you will see when opening some example label maps, the automated labelling is not perfect. This is a common problem in the medical analysis domain, often real expert annotations are sparse and a "silver-standard" ground truth has to be used.

**Preparing the data:**

The data is available online through the Human Connectome Project (HCP) `website <https://www.humanconnectome.org/>`_. To download the data, you need to create a free account. Be sure you downlaod the 100 unrelated subjects.
Once downloaded, you can run ``python bin/prepare_data.py --data_dir=<path_to_downloaded_data>`` (setup environment first, see :ref:`experiments_label`).
The script

- resamples the images and labels to unit voxel (1mm x 1mm x 1mm)
- rescales the image intensities to the full uint16 range (0-65535)
- merges the labels to get the required label maps
- splits the data into 70 training (``./data/train/``) and 30 testing (``./data/test/``) cases
- renames the images by using following prefixes:
    - ``native``: for the images in native space
    - ``mni``: for the images in atlas space
    - ``no_skull``: for the skull-stripped images
    - ``biasfieldcorr``: for the bias field corrected images


You may use training and testing cases combined to evaluate the model performance if you like (k-fold cross-validation, leafe-one-out, ...), but we ask you to do the final analysis with this data splitting to ensure comparability.

Atlas
-------------------
The MR image and label files with 'MNI' are already registered to the `MNI152 atlas <http://www.bic.mni.mcgill.ca/ServicesAtlases/ICBM152NLin2009>`_ using nonlinear FNIRT.
The relevant atlas files are provided on Ilias in the "Data" folder:

- T1-weighted atlas image: ``mni_icbm152_t1_tal_nlin_sym_09a.nii.gz``
- T2-weighted atlas image: ``mni_icbm152_t2_tal_nlin_sym_09a.nii.gz``
- Brain mask: ``mni_icbm152_t1_tal_nlin_sym_09a_mask.nii.gz``


Toy Example
--------------------

The toy example data files in the data directory are taken from the Sherwood library [1]_.

References
--------------------

.. [1] Microsoft Research, Sherwood C++ and C# code library for decision forests, 2012. [Online]. Available: http://research.microsoft.com/en-us/downloads/52d5b9c3-a638-42a1-94a5-d549e2251728/. [Accessed: 16-Mar-2016].
.. [2] Van Essen, D.C., Smith, S.M., Barch, D.M., Behrens, T.E., Yacoub, E., Ugurbil, K. and Wu-Minn HCP Consortium, 2013. `The WU-Minn human connectome project: an overview <http://www.sciencedirect.com/science/article/pii/S1053811913005351>`_. Neuroimage, 80, pp.62-79.
.. [3] Milchenko, M. and Marcus, D., 2013. `Obscuring surface anatomy in volumetric imaging data <https://link.springer.com/article/10.1007/s12021-012-9160-3>`_. Neuroinformatics, 11(1), pp.65-75.
.. [4] Mazziotta, J., Toga, A., Evans, A., Fox, P., Lancaster, J., Zilles, K., Woods, R., Paus, T., Simpson, G., Pike, B. and Holmes, C., 2001. `A probabilistic atlas and reference system for the human brain: International Consortium for Brain Mapping (ICBM) <http://rstb.royalsocietypublishing.org/content/356/1412/1293.short>`_. Philosophical Transactions of the Royal Society of London B: Biological Sciences, 356(1412), pp.1293-1322.
.. [5] Fischl, B., Salat, D.H., Busa, E., Albert, M., Dieterich, M., Haselgrove, C., Van Der Kouwe, A., Killiany, R., Kennedy, D., Klaveness, S. and Montillo, A., 2002. `Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain <http://www.sciencedirect.com/science/article/pii/S089662730200569X>`_. Neuron, 33(3), pp.341-355.
